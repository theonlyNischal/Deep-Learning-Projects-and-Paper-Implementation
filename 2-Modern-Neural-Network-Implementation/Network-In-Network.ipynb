{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to NiN Paper: [Network in Network](https://arxiv.org/pdf/1312.4400)\n",
    "\n",
    "\n",
    "A Network-in-Network block consist of a normal convolutional layer followed by two 1x1 convolution layer. The 1x1 convolution layer acts as a per-pixel fully-connected layer[1x1 Convolution](https://www.coursera.org/lecture/convolutional-neural-networks/networks-in-networks-and-1x1-convolutions-ZTb8x).\n",
    "\n",
    "**Single NiN Block**\n",
    "\n",
    "![Single NiN BLock](assets/nin_block.png)\n",
    "\n",
    "The 1x1 convolutional layer gives us more per-pixel non-linearity.\n",
    "\n",
    "**NiN Model**\n",
    "![NiN Model](assets/nin_model.png)\n",
    "\n",
    "NiN removes the fully connected layers and replace them with global average pooling after reducing the number of channels to the desired number of outputs (e.g., 10 for FashionMNIST)\n",
    "\n",
    "\n",
    "Fully-connected layer are prone to overfitting. Overfitting arises when there are more parameters than required amount of parameters to do certain task. When we use fully-connected layer there will be more than enough parameter and our model will learn noise and other fine-grained details. Learning such details will lead to overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NinNet(nn.Module):\n",
    "    def __init__(self, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.layer1 = self.nin_block(3, 96, 11, 4, 0)\n",
    "        \n",
    "        self.layer2 = self.nin_block(96, 256, 5, 1, 2)\n",
    "        \n",
    "        self.layer3 = self.nin_block(256, 384, 3, 1, 1)\n",
    "        \n",
    "        self.layer4 = self.nin_block(384, output_size, 3, 1, 1)\n",
    "        \n",
    "        self.dropout = nn.Dropout2d(p=0.5)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=5, stride=1, padding=0)\n",
    "    \n",
    "    def nin_block(self, in_channels, out_channels, kernel_size, strides, padding):\n",
    "        layers = list()\n",
    "        \n",
    "        layers = layers + [nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding), nn.ReLU(inplace=True)]\n",
    "        layers = layers + [nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU(inplace=True)]\n",
    "        layers = layers + [nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU(inplace=True)]        \n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer2(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NinNet(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv2d(384, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (dropout): Dropout2d(p=0.5, inplace=False)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (avgpool): AvgPool2d(kernel_size=5, stride=1, padding=0)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_nin = NinNet(10)\n",
    "my_nin = my_nin.double()\n",
    "my_nin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.random.uniform(size=(1, 3, 224, 224))\n",
    "X = torch.from_numpy(X)\n",
    "output = my_nin(X)\n",
    "\n",
    "print(output.shape)\n",
    "\n",
    "## The output is what we desired :) :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
