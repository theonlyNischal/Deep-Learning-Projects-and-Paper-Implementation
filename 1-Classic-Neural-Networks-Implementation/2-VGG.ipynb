{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Reference](https://github.com/bentrevett/pytorch-image-classification/blob/master/4%20-%20VGG.ipynb)\n",
    "\n",
    "Unlike other previous architectures, VGG has given very simple architecture and allows researchers to design new networks by following a general template.\n",
    "\n",
    "Like AlexNet, VGG has two components, one is features consisting of convolutional layers, non-linearity and then a pooling layer and another is classifiers consisting of fully-connected layers. VGG is not a single model instead it consist of a number of different architecture based upon the configuration of convolutional layer.\n",
    "\n",
    "![VGG Configuration](assets/images/vgg_convnet_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load necessary packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Base VGG Architecture\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, features, output_size):\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(7)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, output_size)\n",
    "            \n",
    "            \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next thing we need to do is calculate the features. If we look at the configuration in above image, In VGG, the classifier portion is always same i.e It is 3 fully-connected layer and the number of filters at the last conv layer of classifier is 512. The features in VGG consists of 5 blocks.\n",
    "\n",
    "Typically the VGG Configuration are defined as lists. The integer in the configuration denotes the number of filter and char 'M denotes the max pool layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_config = [64, 64, \"M\", 128, 128, \"M\", 256, 256, \n",
    "                \"M\", 512, 512, 512, \"M\", 512, 512]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define a function that takes vgg configuration as input and returns a nn.Sequential with respect to layers.\n",
    "\n",
    "We can see that we alywas use the same size filter (2x2) and stride(2) in all of our max pool layer i.e We will not overlap in max-pool.\n",
    "\n",
    "For convolutional layers we alywas use the same filter size of 3x3 and padding of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vgg_layers(config):\n",
    "    \n",
    "    layers = list()\n",
    "    in_channels = 3\n",
    "    \n",
    "    for c in config:\n",
    "        \n",
    "        assert c == \"M\" or isinstance(c, int)\n",
    "        \n",
    "        if c == \"M\":\n",
    "            layers = layers + [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, c, 3, 1)\n",
    "            layers = layers + [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = c\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (3): ReLU(inplace=True)\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (6): ReLU(inplace=True)\n",
       "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (8): ReLU(inplace=True)\n",
       "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (11): ReLU(inplace=True)\n",
       "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (13): ReLU(inplace=True)\n",
       "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (16): ReLU(inplace=True)\n",
       "  (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (18): ReLU(inplace=True)\n",
       "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (20): ReLU(inplace=True)\n",
       "  (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (23): ReLU(inplace=True)\n",
       "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (25): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_features = get_vgg_layers(vgg16_config)\n",
    "vgg_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (23): ReLU(inplace=True)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=7)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_size = 10 #\n",
    "vgg16 = VGG(features=vgg_features, output_size=output_size)\n",
    "vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
